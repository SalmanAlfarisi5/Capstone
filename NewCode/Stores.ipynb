{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33bd1ce0",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "143f01ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3291206",
   "metadata": {},
   "source": [
    "Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2800705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRODUCTS_PATH = '../NewData/products.csv'\n",
    "TX_PATH       = '../NewData/sales_transactions.csv'\n",
    "OUT_DIR       = '../NewData/StoresLevel'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99023c74",
   "metadata": {},
   "source": [
    "Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29123534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canonicalize_pairs(df, a='product_id1', b='product_id2'):\n",
    "    \"\"\"Ensure (A,B)==(B,A) and create canonical columns p1,p2.\"\"\"\n",
    "    out = df.copy()\n",
    "    out[a] = out[a].astype(str).str.strip()\n",
    "    out[b] = out[b].astype(str).str.strip()\n",
    "    ij = np.sort(out[[a, b]].values, axis=1)\n",
    "    out['p1'] = ij[:, 0]\n",
    "    out['p2'] = ij[:, 1]\n",
    "    return out\n",
    "\n",
    "def compute_attribute_scores(products_df):\n",
    "    \"\"\"Compute attribute scores for all product pairs (global).\"\"\"\n",
    "    # Prepare columns used in scoring\n",
    "    df = products_df.copy()\n",
    "    df['compatible_vehicle'] = df['compatible_vehicle'].apply(\n",
    "        lambda x: [v.strip() for v in str(x).split(',')] if isinstance(x, str) else []\n",
    "    )\n",
    "\n",
    "    # Precompute min/max for price normalization\n",
    "    min_price = df['unit_price'].min()\n",
    "    max_price = df['unit_price'].max()\n",
    "    price_range = (max_price - min_price) if pd.notna(max_price) and pd.notna(min_price) else 0.0\n",
    "\n",
    "    def _score(a, b):\n",
    "        # Category\n",
    "        s = 0.5 if a['category'] == b['category'] else 0.0\n",
    "        # Grade\n",
    "        s += 0.05 if a['grade'] == b['grade'] else 0.0\n",
    "        # Material\n",
    "        s += 0.05 if a['material'] == b['material'] else 0.0\n",
    "        # Vehicle type\n",
    "        s += 0.15 if a['vehicle_type'] == b['vehicle_type'] else 0.0\n",
    "        # Compatible vehicle intersection\n",
    "        s += 0.15 if set(a['compatible_vehicle']) & set(b['compatible_vehicle']) else 0.0\n",
    "        # Price similarity\n",
    "        if price_range > 0:\n",
    "            s += 0.1 * (1 - abs(a['unit_price'] - b['unit_price']) / price_range)\n",
    "        return float(s)\n",
    "\n",
    "    pairs = []\n",
    "    for i, j in combinations(df.index, 2):\n",
    "        a, b = df.loc[i], df.loc[j]\n",
    "        pairs.append({\n",
    "            'product_id1': a['product_id'],\n",
    "            'product_id2': b['product_id'],\n",
    "            'attribute_score': _score(a, b)\n",
    "        })\n",
    "\n",
    "    attr = pd.DataFrame(pairs)\n",
    "    attr = canonicalize_pairs(attr, 'product_id1', 'product_id2')\n",
    "    attr = attr[['p1', 'p2', 'attribute_score']].drop_duplicates()\n",
    "    return attr\n",
    "\n",
    "def compute_transaction_scores_for_store(tx_store_df):\n",
    "    \"\"\"\n",
    "    Compute transaction_score (0..1) for a single store using:\n",
    "      - Lift → 1/(1+lift)\n",
    "      - Yule's Q → (1 - Q)/2\n",
    "      - ρ(common purchases) → (ρ+1)/2\n",
    "    Then mean of available signals.\n",
    "    \"\"\"\n",
    "    if tx_store_df.empty:\n",
    "        return pd.DataFrame(columns=['p1', 'p2', 'transaction_score'])\n",
    "\n",
    "    # Baskets per transaction\n",
    "    baskets = tx_store_df.groupby('transaction_id')['product_id'].apply(set)\n",
    "    products = sorted(tx_store_df['product_id'].astype(str).unique().tolist())\n",
    "    if len(products) < 2:\n",
    "        return pd.DataFrame(columns=['p1', 'p2', 'transaction_score'])\n",
    "\n",
    "    # Incidence X (TxP) and co-occurrence N\n",
    "    X = pd.crosstab(tx_store_df['transaction_id'], tx_store_df['product_id']).astype(bool).astype(int)\n",
    "    N = X.T.dot(X)  # index=columns=product_id\n",
    "    m = len(products)\n",
    "    n_baskets = X.shape[0]\n",
    "\n",
    "    # Supports\n",
    "    n_i = np.diag(N.to_numpy())\n",
    "    si = n_i / n_baskets\n",
    "\n",
    "    # Row means μ_i over k≠i and centered rows C\n",
    "    mu = (N.sum(axis=1).to_numpy() - n_i) / max(m - 1, 1)\n",
    "    C = N.sub(pd.Series(mu, index=N.index), axis=0)\n",
    "\n",
    "    pairs = []\n",
    "    for i, j in combinations(range(m), 2):\n",
    "        pi, pj = N.index[i], N.index[j]\n",
    "        a = int(N.iat[i, j])\n",
    "        ni, nj = int(n_i[i]), int(n_i[j])\n",
    "        b = ni - a\n",
    "        c = nj - a\n",
    "        d = n_baskets - (a + b + c)\n",
    "\n",
    "        # Lift\n",
    "        s_i, s_j, s_ab = si[i], si[j], a / n_baskets\n",
    "        lift = np.nan if (s_i == 0 or s_j == 0) else (s_ab / (s_i * s_j))\n",
    "        lift_sub = np.nan if (pd.isna(lift) or lift <= 0) else 1.0 / (1.0 + lift)\n",
    "\n",
    "        # Yule's Q (smoothed)\n",
    "        eps = 1e-9\n",
    "        num = (a + eps) * (d + eps) - (b + eps) * (c + eps)\n",
    "        den = (a + eps) * (d + eps) + (b + eps) * (c + eps)\n",
    "        q = num / den\n",
    "        yule_sub = (1 - q) / 2.0\n",
    "\n",
    "        # ρ(common purchases)\n",
    "        ci = C.iloc[i].drop(index=pi)\n",
    "        cj = C.iloc[j].drop(index=pj)\n",
    "        # numerator excludes i and j\n",
    "        num_rho = (C.iloc[i].drop(index=[pi, pj]) * C.iloc[j].drop(index=[pi, pj])).sum()\n",
    "        den_rho = np.sqrt((ci**2).sum() * (cj**2).sum())\n",
    "        rho = np.nan if den_rho == 0 else (num_rho / den_rho)\n",
    "        rho_sub = np.nan if pd.isna(rho) else (rho + 1) / 2.0\n",
    "\n",
    "        # Final transaction score = mean of available signals\n",
    "        sig = np.array([lift_sub, yule_sub, rho_sub], dtype=float)\n",
    "        ts = np.nanmean(sig)\n",
    "        if np.isnan(ts):\n",
    "            ts = 0.5  \n",
    "\n",
    "        pairs.append((str(pi), str(pj), float(ts)))\n",
    "\n",
    "    txn = pd.DataFrame(pairs, columns=['p1', 'p2', 'transaction_score'])\n",
    "    return txn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a9d313",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "015b075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df = pd.read_csv(PRODUCTS_PATH)\n",
    "transactions_df = pd.read_csv(TX_PATH, usecols=['transaction_id', 'product_id', 'store_id'])\n",
    "transactions_df['product_id'] = transactions_df['product_id'].astype(str)\n",
    "products_df['product_id'] = products_df['product_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e41d8f",
   "metadata": {},
   "source": [
    "Compute Attribute Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62cb53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_global = compute_attribute_scores(products_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4656f755",
   "metadata": {},
   "source": [
    "Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7282bddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved store S001: 17766 pairs\n",
      "Saved store S002: 18528 pairs\n",
      "Saved store S003: 18721 pairs\n",
      "Saved store S004: 18528 pairs\n",
      "Saved store S005: 17020 pairs\n",
      "Saved store S006: 17766 pairs\n",
      "Saved store S007: 17955 pairs\n",
      "Saved store S008: 16653 pairs\n",
      "Saved store S009: 17766 pairs\n",
      "Saved store S010: 17578 pairs\n",
      "Saved store S011: 17391 pairs\n",
      "Saved store S012: 15931 pairs\n",
      "Saved store S013: 17020 pairs\n",
      "Saved store S014: 17391 pairs\n",
      "Saved store S015: 16653 pairs\n"
     ]
    }
   ],
   "source": [
    "for store_id, tx_store in transactions_df.groupby('store_id'):\n",
    "    # products present in this store\n",
    "    store_products = set(tx_store['product_id'].astype(str).unique())\n",
    "\n",
    "    # attribute pairs restricted to store's product universe\n",
    "    attr = attr_global[attr_global['p1'].isin(store_products) & attr_global['p2'].isin(store_products)].copy()\n",
    "\n",
    "    # transaction score for this store\n",
    "    txn = compute_transaction_scores_for_store(tx_store[['transaction_id', 'product_id']].copy())\n",
    "\n",
    "    # merge and compute substitute score\n",
    "    df = (attr.merge(txn, on=['p1', 'p2'], how='left')\n",
    "              .rename(columns={'p1': 'product_id1', 'p2': 'product_id2'}))\n",
    "\n",
    "    df['transaction_score'] = df['transaction_score'].astype(float).fillna(0.0)\n",
    "    df['attribute_score']   = df['attribute_score'].astype(float).fillna(0.0)\n",
    "    df['substitute_score']  = (0.6 * df['attribute_score'] + 0.4 * df['transaction_score']).clip(0, 1)\n",
    "\n",
    "    # tidy cols & save\n",
    "    df = df[['product_id1', 'product_id2', 'attribute_score', 'transaction_score', 'substitute_score']]\n",
    "    df.to_csv(os.path.join(OUT_DIR, f'{store_id}.csv'), index=False)\n",
    "\n",
    "    # (optional) quick sanity print\n",
    "    print(f\"Saved store {store_id}: {df.shape[0]} pairs\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
